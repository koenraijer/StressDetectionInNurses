```{r}
library("tidyverse")
library("timetk")
library("readxl")
library("zoo")
library("lubridate")


dir <- paste(getwd(), "/input", sep = "")
dir_list <- list.dirs(path = dir, full.names = F, recursive = F)
baseDir <- dir_list[2]

view(dir_list)
```

## Helper functions

```{r}
# create_time_series
#
# Input: bs_dir (STRING; base directory), data_src (STRING; HR, EDA, TEMP or ACC)
# Output: dataframe with data column and time column (for ACC, the data column contains average body acceleration)

create_time_series <- function(bs_dir, data_src) {
  # Load csv
  tmp <- read.csv(paste("input/", bs_dir, "/", data_src, ".csv", sep = ""))
  
  if (data_src == "ACC") {
    # Load csv
    # Sampling rate
    sr <- tmp[1,1]
    # Start time
    dt <- as_datetime(suppressWarnings(as.numeric(gsub(pattern = "X", replacement = "", fixed = T, x = names(tmp)))), tz = "Europe/Amsterdam")[1]
    # Trim SR off
    tmp <- tmp[-1,]
    
    # Create time column
    time <- seq(from = dt, by = seconds(1 / sr[[1]]), length.out = nrow(tmp))
    
    tmp <- sqrt(tmp[,1]^2 + tmp[,2]^2 + tmp[,3]^2)
  } else {
    # Sampling rate
    sr <- tmp[1,]
    # Start time
    dt <- as_datetime(as.numeric(gsub(pattern = "X", replacement = "", fixed = T, x = names(tmp))), tz = "Europe/Amsterdam")
    # Trim SR off
    tmp <- tmp[-1,]
    
    # Create time column
    time <- seq(from = dt, by = seconds(1 / sr), length.out = length(tmp))
  }

  # Return dataframe
  df <- data.frame(data_src = tmp, TIME = as_datetime(time, tz = "Europe/Amsterdam"), SRC = bs_dir)
  names(df)[1] <- data_src
  return(df)
}

#--------------------------------------------------------------------------------------------
# add_window_index
#
# Input: data_f (DATA.FRAME), window (in seconds), sr (sample rate in Hz)

add_window_index <- function(data_f, window, sr) {
  # Calc no of time windows
  no_tw <- (nrow(data_f) / sr) / window
  data_f$WINDOW <- rep(1:(no_tw+1), each = window*sr, length.out = nrow(data_f))
  
  # Trim of incomplete time windows
  data_f <- data_f %>% filter(WINDOW <= no_tw) 
  
  return(data_f)
}

#--------------------------------------------------------------------------------------------
# Create helper function that takes baseDir, and returns stats_df for that directory
join_data_from_folders <- function(baseDir) {
    hr_ts <- create_time_series(baseDir, "HR")
    eda_ts <- create_time_series(baseDir, "EDA")
    temp_ts <- create_time_series(baseDir, "TEMP")
    acc_ts <- create_time_series(baseDir, "ACC")
    
    # Find max start time and trim all sources to start there
    max_start_time <- max(acc_ts$TIME[1], hr_ts$TIME[1], eda_ts$TIME[1], temp_ts$TIME[1])
    
    hr_ts <- hr_ts %>% filter(TIME >= max_start_time)
    acc_ts <- acc_ts %>% filter(TIME >= max_start_time)
    eda_ts <- eda_ts %>% filter(TIME >= max_start_time)
    temp_ts <- temp_ts %>% filter(TIME >= max_start_time)
    
    # Windowing the time series
    window <- 60 # seconds
    
    hr_ts <- add_window_index(hr_ts, window, 1)
    acc_ts <- add_window_index(acc_ts, window, 32)
    eda_ts <- add_window_index(eda_ts, window, 4)
    temp_ts <- add_window_index(temp_ts, window, 4)
    
    # Find maximum number of windows and trim excess windows
    max_no_windows <- min(max(hr_ts$WINDOW), max(acc_ts$WINDOW), max(eda_ts$WINDOW), max(temp_ts$WINDOW))
    
    hr_ts <- hr_ts %>% filter(WINDOW <= max_no_windows)
    acc_ts <- acc_ts %>% filter(WINDOW <= max_no_windows)
    eda_ts <- eda_ts %>% filter(WINDOW <= max_no_windows)
    temp_ts <- temp_ts %>% filter(WINDOW <= max_no_windows)
    
    # Calculating rolling features per time window (50% overlap)
      # Heart rate
    sr <- 1
    hr_stats <- hr_ts %>% group_by(WINDOW) %>% summarize(
      start_time = min(TIME), 
      end_time = max(TIME), 
      hr_mean = rollapply(HR, width = ((window * sr) / 2), mean, partial = T, by = (window * sr)), 
      hr_sd = rollapply(HR, width = ((window * sr) / 2), sd, partial = T, by = (window * sr)), 
      hr_min = rollapply(HR, width = ((window * sr) / 2), min, partial = T, by = (window * sr)), 
      hr_max = rollapply(HR, width = ((window * sr) / 2), max, partial = T, by = (window * sr)),
    )
    hr_stats <- hr_stats %>% mutate(hr_range = hr_max - hr_min, src = hr_ts$SRC[1])
    
      # Body acceleration
    sr <- 32
    acc_stats <- acc_ts %>% group_by(WINDOW) %>% summarize(
      start_time = min(TIME), 
      end_time = max(TIME), 
      acc_mean = rollapply(ACC, width = ((window * sr) / 2), mean, partial = T, by = (window * sr   )), 
      acc_sd = rollapply(ACC, width = ((window * sr) / 2), sd, partial = T, by = (window * sr)), 
      acc_min = rollapply(ACC, width = ((window * sr) / 2), min, partial = T, by = (window * sr    )), 
      acc_max = rollapply(ACC, width = ((window * sr) / 2), max, partial = T, by = (window * sr    )),
    )
    acc_stats <- acc_stats %>% mutate(acc_range = acc_max - acc_min, src = acc_ts$SRC[1])
    
      # Electrodermal activity
    sr <- 4
    eda_stats <- eda_ts %>% group_by(WINDOW) %>% summarize(
      start_time = min(TIME), 
      end_time = max(TIME), 
      eda_mean = rollapply(EDA, width = ((window * sr) / 2), mean, partial = T, by = (window * sr   )), 
      eda_sd = rollapply(EDA, width = ((window * sr) / 2), sd, partial = T, by = (window * sr)), 
      eda_min = rollapply(EDA, width = ((window * sr) / 2), min, partial = T, by = (window * sr    )), 
      eda_max = rollapply(EDA, width = ((window * sr) / 2), max, partial = T, by = (window * sr    )),
    )
    eda_stats <- eda_stats %>% mutate(eda_range = eda_max - eda_min, src = eda_ts$SRC[1])
    
      # Skin Temperature
    temp_stats <- temp_ts %>% group_by(WINDOW) %>% summarize(
      start_time = min(TIME), 
      end_time = max(TIME), 
      temp_mean = rollapply(TEMP, width = ((window * sr) / 2), mean, partial = T, by = (window * sr   )), 
      temp_sd = rollapply(TEMP, width = ((window * sr) / 2), sd, partial = T, by = (window * sr)), 
      temp_min = rollapply(TEMP, width = ((window * sr) / 2), min, partial = T, by = (window * sr    )), 
      temp_max = rollapply(TEMP, width = ((window * sr) / 2), max, partial = T, by = (window * sr    )),
    )
    temp_stats <- temp_stats %>% mutate(temp_range = temp_max - temp_min, src = temp_ts$SRC[1])
    
    stats_df <- bind_cols(hr_stats[,!(names(hr_stats) %in% c("src"))], acc_stats[,!(names(acc_stats) %in% c("WINDOW", "start_time", "end_time", "src"))], eda_stats[,!(names(eda_stats) %in% c("WINDOW", "start_time", "end_time", "src"))], temp_stats[,!(names(temp_stats) %in% c("WINDOW", "start_time", "end_time"))])
    return(stats_df)
}
```

## Loop over all files in folder

-   Because the final algorithm will use sliding windows from which statistical features are derived, it makes no sense to perform any interpolation, so instead, shorter files within a folder are trimmed to the shortest file.

-   Instead of joining time series of different sample rates, we'll join the statistical features per window.

-   Calculating statistical features of non-overlapping time windows is simple, using `group_by(WINDOW)`, `` summarize(mean = mean(HR)` ``. To calculate rolling windows, I use `rollapply()`, which uses 50% overlap centered at the current window, and calculates the rolling average only once every window (`by = window`).

```{r}
# initiate df final_df
features <- data.frame()

# Loop over all folders
for (i in 1:length(dir_list)) {
  temp_df <- join_data_from_folders(dir_list[i])
  print((paste(nrow(temp_df), "rows added to features, which now has length ", nrow(features), " (", i, "/", length(dir_list))))
  features <- bind_rows(features, temp_df)
  print((paste("length of features: ", nrow(features))))
  
}

# Re-index windows
features <- features %>% mutate(WINDOW = row_number())

view(features)
```

-   Now, in order to preserve computing power, we'll select the windows in the `features` that are in the `survey_results` because we will only use labelled windows.

```{r}
# HELPER FUNCTIONS

check_interval <- function(row) {
  # Assign variables for the column indices of "src", "start_time", and "end_time". 
  src_col_index <- which(names(stats_df) == "src")
  start_time_col_index <- which(names(stats_df) == "start_time")
  end_time_col_index <- which(names(stats_df) == "end_time")
  
  # Filter survey_results to return rows with ID's corresponding to stats_df
  tmp <- filter(survey_results, ID %in% substr(row[src_col_index], 1, 2))
  
  # Find indices in tmp for which contain windows present in stats_df 
  indices <- which(interval(row[start_time_col_index], row[end_time_col_index]) %within% tmp$interval)
  
  # If there is one, find its corresponding stress level and return it.
  if (length(indices) > 0) {
    return(tmp$Stress_level[indices[1]])
  } else {
    return(NA)
  }
}
  

change_date <- function(row, start = F) {
  if(start == F) {
    col_index <- which(names(survey_results) == "End_time")
  } else {
    col_index <- which(names(survey_results) == "Start_time")
  }
  
  date_col_index <- which(names(survey_results) == "date")
  old_dt <- row[col_index]
  new_date <- row[date_col_index]
  
  # Extract time in seconds from old_dt
  old_time <- seconds_to_period(as.numeric(as.POSIXlt(old_dt)$hour)*3600 + as.numeric(as.POSIXlt(old_dt)$min)*60 + as.numeric(as.POSIXlt(old_dt)$sec))
  
  new_dt <- as.POSIXct(as.Date(new_date) + old_time, origin = "1970-01-01", tz = "GMT")
  return(new_dt)
}

# -------------------------------------

# Read in data
survey_results <- read_excel("input/SurveyResults.xlsx", na = "na")
# Add underscores to colnames
names(survey_results) <- gsub(pattern = " ", replacement="_", x = names(survey_results), fixed = T)
# Remove rows where Stress_level is NA
survey_results <- survey_results[!is.na(survey_results$Stress_level),]
# Remove duration column (it's redundant as it will be replaced by the interval col)
survey_results <- survey_results[,-which(names(survey_results) == "duration")]

# Change the date in start_time and end_time to the date in the date column in survey_results
  # - do.call(c, output) ---> this function converts the output of the apply function, which is a list, to a vector.
  # - simplify = F is needed so apply will return POSIXct objects and not numeric values. 
survey_results$Start_time <- do.call(c,apply(survey_results, 1, change_date, start = T, simplify = F))
survey_results$End_time <- do.call(c, apply(survey_results, 1, change_date, simplify = F))

# Add interval column to survey_results
survey_results <- survey_results %>% mutate(interval = interval(survey_results$Start_time, survey_results$End_time))


stress_col <- apply(features, 1, check_interval)
view(stress_col)
```

```{r}
features$stress <- stress_col



# Select only rows with no NAs
features_selected <- na.omit(features)

# Write to CSV
write.csv(features_selected, "data.csv", row.names = F)

```

Current state:

-   The code checks for each time window whether it is within the interval of a validated time period in the survey_results df, and adds that stress value to the stress column in the stats_df.

What to do next:

-   Make the code loop over all available data

After that, I will have a gigantic labelled database that can be used for ML.
